---
title: "Model Evaluation"
author: "Alejandro Hernandez; Hugo Marquez"
date: "2022-08-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# set working directory to project directory (outside of SRC folder)
split <- str_split(getwd(), "/", simplify = TRUE)
wdir <- paste(split[-length(split)], collapse = "/")
knitr::opts_knit$set(root.dir = wdir)
```

```{r, include = FALSE}
library(stringr)
library(mice)
```

# Data Pre-Processing

### Import data and extract features

```{r}
set.seed(28765)
# get training set
train <- read.csv(sprintf("%s/data/train.csv", getwd()), na.strings = "")

# split aggregate columns
train <- separate(train, col=Cabin, into=c("Deck", "Num", "Side"), sep='/')
train <-  separate(train, col=PassengerId , into=c("GroupId", "PersonalId"), sep='_')
train <-  separate(train, col=Name , into=c("FirstName", "LastName"), sep=' ')

# convert GroupId, PersonalId, and Num to type INTEGER
train[c(1,2,6)] <- sapply(train[c(1,2,6)], as.integer)

# convert missing first and last names to "NONE"
# imputation treats NA, and it wouldn't make sense to impute
train <- train %>%
  mutate_at(c('FirstName','LastName'), ~ replace_na(.,"NONE"))

# encode columns of type LOGICAL to INTEGER (TRUE = 1, FALSE = 0)
train <- train %>%
  mutate_if(is.logical, as.integer)

# confirm each variable is the correct type
sapply(train, typeof)
```

### Handle missing values

```{r}
# for now, just toss them
train = na.omit(train)
```

### Split training and validation set

```{r}
# split train dataset into training set (75%) and validation set (25%)
train_index <- createDataPartition(train$Transported, 
                                   p = .75)$Resample1
space_titanic_train <- train[train_index, ]
space_titanic_valid <- train[-train_index, ]

cat("Training set size: ", nrow(space_titanic_train))
cat("Validation set size: ", nrow(space_titanic_valid))
```

# Model Building

```{r}
# Suppose the response variable is deaths and fit the model to the training data; # using drivers as predictor for a linear model;

space_titanic_train$Transported = factor(space_titanic_train$Transported)

space_titanic_train$Transported <- factor(space_titanic_train$Transported, levels =c("0" , "1"))

levels(space_titanic_train$Transported) <- c("0", "1")
```

## K-Nearest Neighbors

```{r}
control <- trainControl(method="cv",number=5)

tr_control <- trainControl(method="cv",number=5, classProbs = TRUE)


fit_knn <- train(Transported ~ VIP + RoomService + FoodCourt + ShoppingMall + Spa,
                 method = "knn",
                 trControl = control,
                 preProcess = c("center","scale"),
                 data = space_titanic_train)
```

## Lasso and Ridge Regression

```{r}
lasso <- train(Transported ~ VIP + RoomService + FoodCourt + ShoppingMall + Spa,
             data = space_titanic_train,
             method = 'glmnet', 
             tuneGrid = expand.grid(alpha = 1, lambda = 1),
             trControl = tr_control 
)

lambda_grid = 10^(seq(-3,1,by=0.1))

ridge <- train(Transported ~ VIP + RoomService + FoodCourt + ShoppingMall + Spa,
             data = space_titanic_train,
             method = 'glmnet', 
             tuneGrid = expand.grid(alpha = 0, lambda = lambda_grid),
             trControl = tr_control 
             
)

# 5-fold cross-validation;

control = trainControl(method="cv", number = 5, classProbs=TRUE)

# methods: "svmLinear", "svmPoly", "svmRadial";
```

## Logistic Regression

```{r}

```

## Support Vector Machine

```{r}
train_svm_lin <- train(Transported ~ VIP + RoomService + FoodCourt + ShoppingMall + Spa ,
                       method = "svmLinear", 
                       trControl = control,  
                       data = space_titanic_train,
                       preProcess = c("center","scale"),  # data should be preprocessed for SVM
                       tuneGrid = expand.grid(C = seq(0.01, 2, length=20))  # tuning parameters go here
                   )


cbind(coef(lasso$finalModel, lasso$finalModel$lambdaOpt),
      coef(ridge$finalModel, ridge$finalModel$lambdaOpt)
      )

train_svm_lin$finalModel
```

## Fully-Connected Neural Network

```{r}

```

# Model Evaluation

```{r}

```


**End of Model Evaluation**
